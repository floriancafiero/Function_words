# functionwords

_Comprehensive multilingual functionâ€‘word datasets with a simple Python API_

---

## Overview
`functionwords` is a lightweight package that ships readyâ€‘toâ€‘use **stopâ€‘lists** (functionâ€‘word lists) for multiple languages and time periods.  Each dataset is stored as a pure JSON resource and loaded on demand through a small, typed API.

Supported out of the box:
| ID        | Language / period                  | Entries |
|-----------|-------------------------------------|---------|
| `fr_21c`  | French â€“ 21stÂ century               | â‰ˆâ€¯610   |
| `en_21c`  | English â€“ 21stÂ century              | â‰ˆâ€¯540   |
| `it_21c`  | Italian â€“ 21stÂ century              | â‰ˆâ€¯520   |
| `es_21c`  | Spanish â€“ 21stÂ century              | â‰ˆâ€¯530   |
| `nl_21c`  | Dutch â€“ 21stÂ century                | â‰ˆâ€¯460   |
| `la_1cbc` | Classical Latin â€“Â 1stÂ c.Â BCE        | â‰ˆâ€¯320   |

You can add further languages or historical stages by dropping new JSON files into `functionwords/datasets/` (or by publishing a plugin packageâ€”see _Extending_ below).

---

## Installation
```bash
pip install functionwords  # once published on PyPI
# or
pip install -e .           # from a cloned repo
```

The library is pure PythonÂ â‰¥â€¯3.8, has **zero runtime dependencies**, and is <20â€¯kB zipped.

---

## Quick start
```python
import functionwords as fw

# List available datasets
print(fw.available_ids())          # ['fr_21c', 'en_21c', ...]

# Load one set (defaults to fr_21c)
fr = fw.load()                     # equivalent to fw.load('fr_21c')
print(fr.name, len(fr.all))        # "French â€“Â 21st century", 610

# Check membership
if 'ne' in fr.all:
    ...

# Build a custom stopâ€‘set: only articles + prepositions
stops = fr.subset(['articles', 'prepositions'])
```

### Commandâ€‘line helpers
```bash
# List dataset IDs
fw-list

# Export every French stopâ€‘word to a text file
fw-export fr_21c -o fr.txt

# Export only conjunctions & negations from Spanish as JSON
fw-export es_21c --include coord_conj subord_conj negations -o es_stop.json
```

---

## File format
Every dataset is a single JSON file with this layout:
```json
{
  "name": "English â€“Â 21st century",
  "language": "en",
  "period": "21c",
  "categories": {
    "articles": ["the", "a", ...],
    "prepositions": ["in", "on", ...],
    ...
  }
}
```
`functionwords` never changes the file in place, so you are free to edit it in your own fork.

---

## Extending
* **Dropâ€‘in**: add `xx_period.json` under `functionwords/datasets/` and rebuild the wheel.
* **Plugin**: distribute a separate package that exposes its folder through the entryâ€‘point group `functionwords_datasets`.  The loader will discover and merge thirdâ€‘party sets automatically.

See `CONTRIBUTING.md` for guidelines on style and minimal coverage.

---

## License
MIT.  The stopâ€‘lists themselves compile publicâ€‘domain words; see source headers for perâ€‘file provenance.

---

## Credits
Built with â¤ by the openâ€‘source community and ChatGPT contributorÂ ðŸ˜Š

